---
# 1) Import custom CRUSH map
- name: Copy CRUSH map
  copy:
    src: "{{ pve_ceph_custom_crushmap }}"
    dest: /tmp/crushmap.txt

- name: Compile CRUSH map
  command: crushtool -c /tmp/crushmap.txt -o /tmp/crushmap.bin

- name: Apply CRUSH map
  command: ceph osd setcrushmap -i /tmp/crushmap.bin

# 2) CSI Ceph pools
- name: Create CSI Ceph pools
  community.general.ceph_pool:
    name: "{{ item.name }}"
    pg_num: "{{ item.pg_num }}"
    type: "{{ item.type }}"
    crush_rule: "{{ item.rule }}"
  loop: "{{ ceph_csi_pools }}"

# 3) CephFS filesystems
- name: Create CephFS filesystems
  community.general.ceph_fs:
    name: "{{ item.name }}"
    metadata_pool: "{{ item.metadata_pool }}"
    data_pool: "{{ item.data_pool }}"
  loop: "{{ ceph_csi_fs }}"

# 4) CSI client keys
- name: Create CSI CephX client keys
  community.general.ceph_auth:
    name: "{{ item.entity }}"
    caps: "{{ item.caps }}"
    state: present
  loop: "{{ ceph_csi_clients.values() | list }}"

# 5) CephFS subvolume groups
- name: Create CephFS subvolume groups
  command: >
    ceph fs subvolume group create
    {{ item.fs }} {{ item.group }}
  loop: "{{ ceph_csi_subvol_groups }}"

# 6) Static PV subvolumes
- name: Create static PV subvolumes
  command: >
    ceph fs subvolume create
    {{ item.fs }} {{ item.subvol }} --group {{ item.group }}
  loop: "{{ ceph_csi_static_subvols }}"

# 7) Proxmox storage definitions
- name: Add Ceph RBD storage to PVE
  community.general.proxmox_storage:
    api_host:     "{{ ansible_host }}"
    api_user:     "root@pam"
    api_password: "{{ proxmox_password }}"
    storage:      rbd
    type:         rbd
    pool:         rbd
    content:      images,rootdir,backup
    monhost:      "{{ groups.pve | map('extract', hostvars, 'ansible_host') | join(',') }}"
    nodes:        "{{ groups.pve | join(',') }}"

- name: Add CephFS storage to PVE
  community.general.proxmox_storage:
    api_host:     "{{ ansible_host }}"
    api_user:     "root@pam"
    api_password: "{{ proxmox_password }}"
    storage:      cephfs
    type:         cephfs
    export:       data
    content:      iso,vztmpl,rootdir
    path:         /mnt/pve/cephfs
    nodes:        "{{ groups.pve | join(',') }}"

# 8) Ceph MGR modules & dashboard
- name: Enable Ceph Dashboard module
  command: ceph mgr module enable dashboard
  args: { warn: false }

- name: Create Ceph Dashboard admin user
  command: >
    ceph dashboard ac-user-create admin adminpassword
    mon 'allow *' osd 'allow *' mds 'allow'
  args: { warn: false }

- name: Enable Prometheus exporter
  command: ceph mgr module enable prometheus
  args: { warn: false }

- name: Expose Prometheus metrics
  command: ceph config set mgr/prometheus/server_addr 0.0.0.0

# 9) Ceph tuning
- name: Set mon_osd_full_ratio to 85%
  command: ceph config set mon mon_osd_full_ratio 0.85

- name: Set mon_osd_nearfull_ratio to 80%
  command: ceph config set mon mon_osd_nearfull_ratio 0.80

- name: Tune OSD operation threads
  command: ceph config set osd osd_op_threads 32

- name: Tune filestore_max_sync_interval to 5s
  command: ceph config set osd filestore_max_sync_interval 5
