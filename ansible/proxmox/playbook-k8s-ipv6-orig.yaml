---
- name: Bootstrap & join control-plane and workers (IPv6‑only)
  hosts: all
  become: true

  vars:
    control_plane_group: controlplane
    worker_group:        worker

    # no port here; Cilium BGP will advertise this
    k8s_api_vip:        "fd00:101::ac"
    k8s_version_major:  "1.32"
    ipv6_pod_cidr:      "fd00:101:44::/60"
    ipv6_service_cidr:  "fd00:101:96::/108"
    install_stage:      "full"   # prereqs | k8s | full

    cilium_helm_values:
      kubeProxyReplacement: true
      k8sServiceHost: "{{ k8s_api_vip }}"
      k8sServicePort: 6443
      ipam:
        mode: cluster-pool
        clusterPoolIPv6PodCIDR: "{{ ipv6_pod_cidr }}"
        clusterPoolIPv6MaskSize: 64
      enableIPv6: true
      enableIPv4: false
      bgpControlPlane:
        enabled: true
        localASN: 65101
        peers:
          - peerAddress: "fd00:255::fffe"
            peerASN:     65000
      service:
        loadBalancer:
          mode: bgp
      hubble:
        relay: { enabled: true }
        ui:    { enabled: true }
      l2announcements: { enabled: true }
      ingressController:
        enabled: true
        mode:    dedicated

  tasks:
    # 1) APT prereqs + sysctl
    - name: Add Kubernetes APT key
      ansible.builtin.apt_key:
        url:      "https://pkgs.k8s.io/core:/stable:/v{{ k8s_version_major }}/deb/Release.key"
        keyring:  /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        state:    present

    - name: Add Kubernetes APT repository
      ansible.builtin.apt_repository:
        repo: >
          deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg]
          https://pkgs.k8s.io/core:/stable:/v{{ k8s_version_major }}/deb/ /
        filename: kubernetes
        state:    present

    - name: Update apt cache
      ansible.builtin.apt:
        update_cache: true

    - name: Persist IPv6 forwarding across reboots
      ansible.builtin.sysctl:
        name:       net.ipv6.conf.all.forwarding
        value:      "1"
        sysctl_set: yes
        reload:     yes

    # 2) pick up exact kubernetes version
    - name: Discover latest k8s patch for v{{ k8s_version_major }}
      ansible.builtin.shell: |
        apt-cache madison kubelet \
          | awk '/{{ k8s_version_major }}\./ {print $3}' \
          | sort -Vr | head -n1
      register: k8s_patch
      changed_when: false

    - name: Fail if no matching patch found
      ansible.builtin.fail:
        msg: "No kubelet version matching {{ k8s_version_major }}; got: {{ k8s_patch.stdout }}"
      when: k8s_patch.stdout == ""

    - name: Set k8s_version fact
      ansible.builtin.set_fact:
        k8s_version: "{{ k8s_patch.stdout }}"

    - name: Install kubelet, kubeadm, kubectl
      ansible.builtin.apt:
        name:
          - "kubelet={{ k8s_version }}"
          - "kubeadm={{ k8s_version }}"
          - "kubectl={{ k8s_version }}"
        state: present
        update_cache: false

    # 3) initialize first control-plane
    - name: Render kubeadm init config (primary only)
      ansible.builtin.template:
        src:  kubeadm-init.yaml.j2
        dest: /root/kubeadm-init.yaml
      when: inventory_hostname == groups[control_plane_group][0]

    - name: Initialize primary control plane
      ansible.builtin.command:
        cmd: kubeadm init --upload-certs --config /root/kubeadm-init.yaml
        creates: /etc/kubernetes/admin.conf
      register: kubeadm_init
      when: inventory_hostname == groups[control_plane_group][0]

    - name: Fail if kubeadm init failed
      ansible.builtin.fail:
        msg: "kubeadm init failed: {{ kubeadm_init.stderr }}"
      when:
        - inventory_hostname == groups[control_plane_group][0]
        - kubeadm_init.rc != 0

    - name: Bring VIP up on loopback (primary only)
      ansible.builtin.command:
        cmd: ip -6 addr add {{ k8s_api_vip }}/128 dev lo
      when: inventory_hostname == groups[control_plane_group][0]

    - name: Wait for API server to answer on VIP (primary only)
      ansible.builtin.wait_for:
        host:    "{{ k8s_api_vip }}"
        port:    6443
        state:   started
        timeout: 300
      when: inventory_hostname == groups[control_plane_group][0]

    - name: Extract control‑plane join command
      ansible.builtin.set_fact:
        control_plane_join_cmd: >-
          {{ kubeadm_init.stdout
             | regex_search('kubeadm join[\\s\\S]*?--control-plane[^\\n]*', '\\0')
             | replace('\\\n',' ') | replace('\\','') | trim }}
      when: inventory_hostname == groups[control_plane_group][0]

    - name: Extract worker join command
      ansible.builtin.set_fact:
        worker_join_cmd: >-
          {{ kubeadm_init.stdout
             | regex_search('kubeadm join[\\s\\S]*?--discovery-token-ca-cert-hash[^\\n]*', '\\0')
             | replace('\\\n',' ') | replace('\\','') | trim }}
      when: inventory_hostname == groups[control_plane_group][0]

    # 4) distribute those two variables to everyone
    - name: Distribute join commands
      ansible.builtin.set_fact:
        control_plane_join_cmd: "{{ hostvars[ groups[control_plane_group][0] ].control_plane_join_cmd }}"
        worker_join_cmd:        "{{ hostvars[ groups[control_plane_group][0] ].worker_join_cmd }}"

    # 5a) Join additional control‑plane nodes
    - name: Join additional control‑plane nodes
      ansible.builtin.command:
        cmd: "{{ control_plane_join_cmd }} --cri-socket /run/containerd/containerd.sock"
        creates: /etc/kubernetes/kubelet.conf
      when:
        - inventory_hostname in groups[control_plane_group]
        - inventory_hostname != groups[control_plane_group][0]

    # 5b) Join worker nodes
    - name: Join worker nodes
      ansible.builtin.command:
        cmd: "{{ worker_join_cmd }} --cri-socket /run/containerd/containerd.sock"
        creates: /etc/kubernetes/kubelet.conf
      when: inventory_hostname in groups[worker_group]

- name: Install & configure Cilium via Helm (primary only)
  hosts: "{{ groups[control_plane_group][0] }}"
  become: true

  tasks:
    - name: Ensure Helm is installed
      ansible.builtin.shell: |
        curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
      args:
        creates:    /usr/local/bin/helm
        executable: /bin/bash

    - name: Copy admin kubeconfig for Helm
      ansible.builtin.copy:
        src:        /etc/kubernetes/admin.conf
        dest:       /root/.kube/config
        remote_src: true
        mode:       "0600"

    - name: Add Cilium Helm repo
      kubernetes.core.helm_repository:
        name:     cilium
        repo_url: https://helm.cilium.io

    - name: Deploy Cilium
      kubernetes.core.helm:
        name:              cilium
        chart_ref:         cilium/cilium
        release_namespace: kube-system
        values:            "{{ cilium_helm_values }}"
        create_namespace:  false
        kubeconfig:        /root/.kube/config
