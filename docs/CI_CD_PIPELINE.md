# GitHub Actions CI/CD Pipeline

## Overview

This document describes the GitHub Actions-based CI/CD pipeline for automating Kubernetes cluster provisioning in your homelab infrastructure.

## üéØ Goals

- **Automate end-to-end** Talos cluster provisioning (Terraform ‚Üí VMs ‚Üí Talos ‚Üí K8s ‚Üí Flux)
- **Self-hosted execution** with Proxmox API access
- **IPv6-first networking** with dual-stack support
- **Incremental adoption** without disrupting existing workflows
- **GitOps-native** integration with Flux CD
- **Immutable infrastructure** using Talos Linux

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     GitHub Repository                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                  Pull Request                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  terraform/live/clusters/cluster-101/                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ terragrunt.hcl (changed)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                                            ‚îÇ
‚îÇ                 ‚ñº                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Workflow: terraform-plan.yml                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Checkout code                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Setup SOPS/Terraform/Terragrunt                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Run: terragrunt plan                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Comment plan output on PR                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                                            ‚îÇ
‚îÇ                 ‚ñº                                            ‚îÇ
‚îÇ         [Developer reviews plan]                             ‚îÇ
‚îÇ                 ‚îÇ                                            ‚îÇ
‚îÇ                 ‚ñº                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           Merge to main                               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                                            ‚îÇ
‚îÇ                 ‚ñº                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Workflow: cluster-provision-talos.yml               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 1: Terraform Apply                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> Provision VMs with Talos NoCloud image       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 2: Wait for VMs                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> Check Talos API responding                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 3: Generate Talos Machine Configs             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> talosctl gen config with IPv6 networking     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 4: Apply Talos Configurations                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> talosctl apply-config to all nodes           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 5: Bootstrap Kubernetes                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> talosctl bootstrap on first control plane    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 6: Configure RouterOS                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> Setup BGP peers for all nodes                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 7: Install Flux CD                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> Bootstrap Flux from GitHub                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Step 8: Verify Health                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ> Check Talos, etcd, nodes, VIP, pods          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                                            ‚îÇ
‚îÇ                 ‚ñº                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Cluster Ready for GitOps!                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Flux syncs apps from kubernetes/clusters/production ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÇ Components

### GitHub Actions Workflows

| Workflow | Trigger | Purpose |
|----------|---------|---------|
| `terraform-plan.yml` | PR to `main` | Validate Terraform changes, post plan as PR comment |
| `cluster-provision-talos.yml` | Manual dispatch | Provision Talos-based K8s cluster |
| `cluster-destroy.yml` | Manual dispatch | Safely tear down a cluster |
| `flux-validate.yml` | PR to `main` | Lint and validate Kubernetes manifests |

### Helper Scripts

Located in `.github/scripts/`:

| Script | Purpose |
|--------|---------|
| `provision-cluster-talos.sh` | Orchestrates entire Talos cluster lifecycle |
| `wait-for-vms.sh` | Waits for VMs to have Talos API responding |
| `configure-routeros.sh` | Configures BGP peering and static routes on RouterOS |
| `verify-cluster-health.sh` | Runs comprehensive post-provision health checks |

### Ansible Playbooks

New playbooks in `ansible/k8s/playbooks/`:

| Playbook | Purpose |
|----------|---------|
| `bootstrap-kubernetes.yml` | Initialize K8s with kubeadm, join nodes, label topology |
| `verify-cluster.yml` | Verify node health, BGP status, VIP reachability |

### Terraform Modules

| Module | Purpose |
|--------|---------|
| `terraform/modules/pve/routeros-config/` | Automated RouterOS BGP configuration (NEW) |

## üöÄ Usage

### Provision a Cluster via GitHub Actions

1. **Navigate** to Actions tab in GitHub
2. **Select** "Provision Cluster (Debian)"
3. **Click** "Run workflow"
4. **Configure**:
   - Cluster ID: `101`, `102`, etc.
   - Action: `plan` or `apply`
   - Options: Skip Flux, Skip Verify
5. **Run** and monitor logs

### Provision Locally

```bash
# Dry run to see what would happen
./.github/scripts/provision-cluster-debian.sh 101 plan

# Apply changes
./.github/scripts/provision-cluster-debian.sh 101 apply

# Apply without Flux
./.github/scripts/provision-cluster-debian.sh 101 apply --skip-flux

# Destroy cluster
./.github/scripts/provision-cluster-debian.sh 101 destroy
```

### Test Terraform Changes via PR

1. **Create** a feature branch
2. **Modify** `terraform/live/clusters/cluster-101/cluster.hcl`
3. **Push** to GitHub
4. **Open** PR
5. **Review** Terraform plan in PR comments
6. **Merge** to trigger provisioning (if workflow configured)

## üîê Prerequisites

### Self-Hosted Runner

The workflows require a self-hosted GitHub Actions runner with:

1. **Network Access**:
   - Proxmox API (HTTPS)
   - RouterOS API (HTTPS)
   - SSH to all cluster VMs

2. **Installed Tools**:
   ```bash
   # Core tools
   terraform >= 1.5
   terragrunt >= 0.50
   ansible >= 2.15
   kubectl >= 1.28
   flux >= 2.1

   # Utilities
   jq
   curl
   ssh
   ```

3. **Authentication**:
   - SSH keys for Ansible (in `~/.ssh/`)
   - Proxmox credentials (via SOPS)
   - GitHub token (for Flux bootstrap)

### GitHub Secrets

Configure these in **Settings ‚Üí Secrets ‚Üí Actions**:

| Secret | Description | Example |
|--------|-------------|---------|
| `SOPS_AGE_KEY` | Your SOPS Age private key | `AGE-SECRET-KEY-1...` |
| `FLUX_GITHUB_TOKEN` | GitHub PAT for Flux | `ghp_...` |

### Repository Setup

1. **Enable Actions**: Settings ‚Üí Actions ‚Üí Allow all actions
2. **Add Self-Hosted Runner**: Settings ‚Üí Actions ‚Üí Runners ‚Üí New runner
3. **Configure Secrets**: As listed above

## üìñ Detailed Documentation

- **[Implementation Guide](./CI_CD_PIPELINE_IMPLEMENTATION.md)** - Complete file contents and examples
- **[Cluster Provisioning](./CLUSTER_PROVISIONING.md)** - Manual provisioning steps (for reference)
- **[RouterOS BGP Setup](./ROS_BGP_CHANGES_NEEDED.md)** - Manual RouterOS configuration (legacy)

## üîÑ Workflow Details

### terraform-plan.yml

**Triggers**: Pull Request modifying `terraform/**`

**Steps**:
1. Checkout code
2. Setup SOPS Age key
3. Install Terraform & Terragrunt
4. Run `terragrunt plan`
5. Comment plan output on PR

**Benefits**:
- Catch errors before merge
- Visibility into infrastructure changes
- Safe change review process

### cluster-provision-debian.yml

**Triggers**:
- Manual dispatch (workflow_dispatch)
- Push to `main` modifying `terraform/live/clusters/**` (optional)

**Inputs**:
- `cluster_id`: Which cluster (101, 102, etc.)
- `action`: plan or apply
- `skip_flux`: Skip Flux installation
- `skip_verify`: Skip health checks

**Steps**:
1. **Terraform Apply**: Provision VMs via Terragrunt
2. **Wait for VMs**: Check SSH and cloud-init completion
3. **Configure RouterOS**: Setup BGP peers and routes
4. **Bootstrap Kubernetes**: Run Ansible playbook
5. **Install Flux**: Bootstrap Flux CD from GitHub
6. **Verify Health**: Run health checks

**Duration**: ~15-20 minutes for full cluster

### cluster-destroy.yml

**Triggers**: Manual dispatch only

**Safety Features**:
- Requires manual confirmation input
- Drains workloads first
- Removes BGP routes before destroying VMs
- Cleanup verification

## üß™ Testing Strategy

### Phase 1: Local Testing

```bash
# Test orchestration script locally
./.github/scripts/provision-cluster-debian.sh 101 plan --dry-run

# Test individual helpers
./.github/scripts/wait-for-vms.sh 101
./.github/scripts/verify-cluster-health.sh 101
```

### Phase 2: Workflow Testing

```bash
# Enable dry-run mode in workflow
# Test on cluster-102 (new cluster)
# Monitor logs carefully
```

### Phase 3: Production Rollout

```bash
# Use on cluster-103+ for new clusters
# Gradually migrate existing clusters
# Keep manual process as backup
```

## üéõÔ∏è Configuration

### Customize Cluster Settings

Edit `terraform/live/clusters/cluster-XXX/cluster.hcl`:

```hcl
cluster_name = "sol"
cluster_id   = 101

control_plane = {
  instance_count = 3
  cpu_count      = 2
  memory_mb      = 8192
  disk_size_gb   = 20
}

workers = {
  instance_count = 3
  cpu_count      = 2
  memory_mb      = 16384
  disk_size_gb   = 100
}
```

### Customize Workflow Behavior

Edit `.github/workflows/cluster-provision-debian.yml`:

```yaml
# Change timeout
timeout-minutes: 60

# Add more cluster IDs
inputs:
  cluster_id:
    options:
      - '101'
      - '102'
      - '103'  # Add new clusters here
```

## üêõ Troubleshooting

### Workflow fails at Terraform step

**Symptoms**: Error during `terragrunt apply`

**Checks**:
- ‚úÖ SOPS Age key correct in GitHub Secrets
- ‚úÖ Runner has network access to Proxmox
- ‚úÖ Proxmox credentials valid in `terraform/live/common/secrets.sops.yaml`

**Debug**:
```bash
# Test locally
cd terraform/live/clusters/cluster-101
terragrunt plan
```

### VMs don't become ready

**Symptoms**: Timeout in "Wait for VMs" step

**Checks**:
- ‚úÖ VMs are powered on in Proxmox
- ‚úÖ Cloud-init completed: `ssh root@VM_IP cloud-init status`
- ‚úÖ Network connectivity from runner to VMs

**Debug**:
```bash
# Check cloud-init logs
ssh root@<VM_IP> journalctl -u cloud-init

# Check Proxmox console
# PVE ‚Üí VM ‚Üí Console
```

### BGP sessions not established

**Symptoms**: Health check fails on BGP verification

**Checks**:
- ‚úÖ FRR running: `ssh root@VM_IP systemctl status frr`
- ‚úÖ BGP config correct: `ssh root@VM_IP vtysh -c 'show run'`
- ‚úÖ RouterOS peers configured
- ‚úÖ Firewall allows BGP (TCP 179)

**Debug**:
```bash
# Check FRR status
ssh root@<VM_IP> vtysh -c 'show bgp summary'

# Check RouterOS
ssh admin@routeros.local
/routing/bgp/connection print
/routing/bgp/session print
```

### Flux bootstrap fails

**Symptoms**: Error during Flux installation

**Checks**:
- ‚úÖ GitHub token valid and has repo permissions
- ‚úÖ Repository path exists: `kubernetes/clusters/production`
- ‚úÖ SOPS Age key in correct location on nodes

**Debug**:
```bash
# Test Flux manually
flux check --pre
flux bootstrap github --help
```

## üìä Monitoring

### GitHub Actions Dashboard

Monitor workflow runs:
- **Actions Tab**: See all workflow runs
- **Status Badges**: Add to README
- **Notifications**: Configure in Settings ‚Üí Notifications

### Workflow Status in README

Add this badge to your README.md:

```markdown
![Cluster Provision](https://github.com/YOUR_USERNAME/home-ops/workflows/Provision%20Cluster%20(Debian)/badge.svg)
```

### Slack/Discord Notifications (Future)

Configure webhook notifications for:
- Workflow started
- Workflow succeeded
- Workflow failed

## üîÆ Future Enhancements

### Planned Features

1. **Talos Support** - Full Talos Linux pipeline
2. **Multi-Cluster** - Provision multiple clusters in parallel
3. **Blue/Green Deployments** - Zero-downtime cluster upgrades
4. **Automated Testing** - Smoke tests after provisioning
5. **Cost Tracking** - Resource usage metrics per cluster
6. **Monitoring Integration** - Prometheus metrics for provisioning

### Community Contributions

Want to contribute? Areas for improvement:

- Better error handling in scripts
- More comprehensive health checks
- Support for other virtualization platforms
- Windows runner support
- Integration with ArgoCD

## üìö References

- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Terraform Proxmox Provider](https://registry.terraform.io/providers/bpg/proxmox/latest/docs)
- [Terragrunt](https://terragrunt.gruntwork.io/)
- [Flux CD](https://fluxcd.io/)
- [SOPS](https://github.com/getsops/sops)

## üÜò Support

For issues or questions:

1. Check [Troubleshooting](#troubleshooting) section
2. Review workflow logs in GitHub Actions
3. Test components locally before filing issue
4. Provide full error logs and context

## üìù License

This automation is part of the home-ops repository.

---

**Status**: üöß Work in Progress

**Last Updated**: 2025-01-10

**Maintainer**: @sulibot
