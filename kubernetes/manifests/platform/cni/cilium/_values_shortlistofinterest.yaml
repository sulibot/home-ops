
hubble:
  relay:
    enabled: true
  ui:
    enabled: true

l2announcements:
  # -- Enable L2 announcements
  enabled: false
  # -- If a lease is not renewed for X duration, the current leader is considered dead, a new leader is picked
  # leaseDuration: 15s
  # -- The interval at which the leader will renew the lease
  # leaseRenewDeadline: 5s
  # -- The timeout between retries if renewal fails
  # leaseRetryPeriod: 2s
# -- Configure L2 pod announcements
l2podAnnouncements:
  # -- Enable L2 pod announcements
  enabled: false
  # -- Interface used for sending Gratuitous ARP pod announcements
  interface: "eth0"
# -- This feature set enables virtual BGP routers to be created via
# CiliumBGPPeeringPolicy CRDs.
bgpControlPlane:
  # -- Enables the BGP control plane.
  enabled: false
  # -- SecretsNamespace is the namespace which BGP support will retrieve secrets from.
  secretsNamespace:
    # -- Create secrets namespace for BGP secrets.
    create: false
    # -- The name of the secret namespace to which Cilium agents are given read access
    name: kube-system
  # -- Status reporting settings (BGPv2 only)
  statusReport:
    # -- Enable/Disable BGPv2 status reporting
    # It is recommended to enable status reporting in general, but if you have any issue
    # such as high API server load, you can disable it by setting this to false.
    enabled: true

bpf:
  autoMount:
    # -- Enable automatic mount of BPF filesystem
    # When `autoMount` is enabled, the BPF filesystem is mounted at
    # `bpf.root` path on the underlying host and inside the cilium agent pod.
    # If users disable `autoMount`, it's expected that users have mounted
    # bpffs filesystem at the specified `bpf.root` volume, and then the
    # volume will be mounted inside the cilium agent pod at the same path.
    enabled: true
  # -- Configure the mount point for the BPF filesystem
  root: /sys/fs/bpf
  # -- Enables pre-allocation of eBPF map values. This increases
  # memory usage but can reduce latency.
  preallocateMaps: false
  # @schema
  # type: [null, integer]
  # @schema
  # -- (int) Configure the maximum number of entries in auth map.
  # @default -- `524288`
  authMapMax: ~
  # -- Enable CT accounting for packets and bytes
  ctAccounting: false
  # @schema
  # type: [null, integer]
  # @schema
  # -- (int) Configure the maximum number of entries in the TCP connection tracking
  # table.
  # @default -- `524288`
  ctTcpMax: ~
  # @schema
  # type: [null, integer]
  # @schema
  # -- (int) Configure the maximum number of entries for the non-TCP connection
  # tracking table.
  # @default -- `262144`
  ctAnyMax: ~
  # -- Control events generated by the Cilium datapath exposed to Cilium monitor and Hubble.
  # Helm configuration for BPF events map rate limiting is experimental and might change
  # in upcoming releases.
  events:
    # -- Default settings for all types of events except dbg and pcap.
    default:
      # -- (int) Configure the limit of messages per second that can be written to
      # BPF events map. The number of messages is averaged, meaning that if no messages
      # were written to the map over 5 seconds, it's possible to write more events
      # in the 6th second. If rateLimit is greater than 0, non-zero value for burstLimit must
      # also be provided lest the configuration is considered invalid. Setting both burstLimit
      # and rateLimit to 0 disables BPF events rate limiting.
      # @default -- `0`
      rateLimit: ~
      # -- (int) Configure the maximum number of messages that can be written to BPF events
      # map in 1 second. If burstLimit is greater than 0, non-zero value for rateLimit must
      # also be provided lest the configuration is considered invalid. Setting both burstLimit
      # and rateLimit to 0 disables BPF events rate limiting.
      # @default -- `0`
      burstLimit: ~
    drop:
      # -- Enable drop events.
      enabled: true
    policyVerdict:
      # -- Enable policy verdict events.
      enabled: true
    trace:
      # -- Enable trace events.
      enabled: true
  # @schema
  # type: [null, integer]
  # @schema
  # -- Configure the maximum number of service entries in the
  # load balancer maps.
  lbMapMax: 65536
  # @schema
  # type: [null, integer]
  # @schema
  # -- (int) Configure the maximum number of entries for the NAT table.
  # @default -- `524288`
  natMax: ~
  # @schema
  # type: [null, integer]
  # @schema
  # -- (int) Configure the maximum number of entries for the neighbor table.
  # @default -- `524288`
  neighMax: ~
  # @schema
  # type: [null, integer]
  # @schema
  # @default -- `16384`
  # -- (int) Configures the maximum number of entries for the node table.
  nodeMapMax: ~
  # -- Configure the maximum number of entries in endpoint policy map (per endpoint).
  # @schema
  # type: [null, integer]
  # @schema
  policyMapMax: 16384
  # @schema
  # type: [null, number]
  # @schema
  # -- (float64) Configure auto-sizing for all BPF maps based on available memory.
  # ref: https://docs.cilium.io/en/stable/network/ebpf/maps/
  # @default -- `0.0025`
  mapDynamicSizeRatio: ~
  # -- Configure the level of aggregation for monitor notifications.
  # Valid options are none, low, medium, maximum.
  monitorAggregation: medium
  # -- Configure the typical time between monitor notifications for
  # active connections.
  monitorInterval: "5s"
  # -- Configure which TCP flags trigger notifications when seen for the
  # first time in a connection.
  monitorFlags: "all"
  # -- (bool) Allow cluster external access to ClusterIP services.
  # @default -- `false`
  lbExternalClusterIP: false
  # -- (bool) Enable loadBalancerSourceRanges CIDR filtering for all service
  # types, not just LoadBalancer services. The corresponding NodePort and
  # ClusterIP (if enabled for cluster-external traffic) will also apply the
  # CIDR filter.
  # @default -- `false`
  lbSourceRangeAllTypes: false
  # -- (bool) Enable the option to define the load balancing algorithm on
  # a per-service basis through service.cilium.io/lb-algorithm annotation.
  # @default -- `false`
  lbAlgorithmAnnotation: false
  # -- (bool) Enable the option to define the load balancing mode (SNAT or DSR)
  # on a per-service basis through service.cilium.io/forwarding-mode annotation.
  # @default -- `false`
  lbModeAnnotation: false
  # @schema
  # type: [null, boolean]
  # @schema
  # -- (bool) Enable native IP masquerade support in eBPF
  # @default -- `false`
  masquerade: ~
  # @schema
  # type: [null, boolean]
  # @schema
  # -- (bool) Configure whether direct routing mode should route traffic via
  # host stack (true) or directly and more efficiently out of BPF (false) if
  # the kernel supports it. The latter has the implication that it will also
  # bypass netfilter in the host namespace.
  # @default -- `false`
  hostLegacyRouting: ~
  # @schema
  # type: [null, boolean]
  # @schema
  # -- (bool) Configure the eBPF-based TPROXY (beta) to reduce reliance on iptables rules
  # for implementing Layer 7 policy.
  # @default -- `false`
  tproxy: ~
  # @schema
  # type: [null, array]
  # @schema
  # -- (list) Configure explicitly allowed VLAN id's for bpf logic bypass.
  # [0] will allow all VLAN id's without any filtering.
  # @default -- `[]`
  vlanBypass: ~
  # -- (bool) Disable ExternalIP mitigation (CVE-2020-8554)
  # @default -- `false`
  disableExternalIPMitigation: false
  # -- (bool) Attach endpoint programs using tcx instead of legacy tc hooks on
  # supported kernels.
  # @default -- `true`
  enableTCX: true
  # -- (string) Mode for Pod devices for the core datapath (veth, netkit, netkit-l2, lb-only)
  # @default -- `veth`
  datapathMode: veth
# -- Enable BPF clock source probing for more efficient tick retrieval.


ingressController:
  # -- Enable cilium ingress controller
  # This will automatically set enable-envoy-config as well.
  enabled: false
  # -- Set cilium ingress controller to be the default ingress controller
  # This will let cilium ingress controller route entries without ingress class set
  default: false
  # -- Default ingress load balancer mode
  # Supported values: shared, dedicated
  # For granular control, use the following annotations on the ingress resource:
  # "ingress.cilium.io/loadbalancer-mode: dedicated" (or "shared").
  loadbalancerMode: dedicated
  # -- Enforce https for host having matching TLS host in Ingress.
  # Incoming traffic to http listener will return 308 http error code with respective location in header.
  enforceHttps: true
  # -- Enable proxy protocol for all Ingress listeners. Note that _only_ Proxy protocol traffic will be accepted once this is enabled.
  enableProxyProtocol: false
  # -- IngressLBAnnotations are the annotation and label prefixes, which are used to filter annotations and/or labels to propagate from Ingress to the Load Balancer service
  ingressLBAnnotationPrefixes: ['lbipam.cilium.io', 'nodeipam.cilium.io', 'service.beta.kubernetes.io', 'service.kubernetes.io', 'cloud.google.com']
  # @schema
  # type: [null, string]
  # @schema
  # -- Default secret namespace for ingresses without .spec.tls[].secretName set.
  defaultSecretNamespace:
  # @schema
  # type: [null, string]
  # @schema
  # -- Default secret name for ingresses without .spec.tls[].secretName set.
  defaultSecretName:
  # -- SecretsNamespace is the namespace in which envoy SDS will retrieve TLS secrets from.
  secretsNamespace:
    # -- Create secrets namespace for Ingress.
    create: true
    # -- Name of Ingress secret namespace.
    name: cilium-secrets
    # -- Enable secret sync, which will make sure all TLS secrets used by Ingress are synced to secretsNamespace.name.
    # If disabled, TLS secrets must be maintained externally.
    sync: true
  # -- Load-balancer service in shared mode.
  # This is a single load-balancer service for all Ingress resources.
  service:
    # -- Service name
    name: cilium-ingress
    # -- Labels to be added for the shared LB service
    labels: {}
    # -- Annotations to be added for the shared LB service
    annotations: {}
    # -- Service type for the shared LB service
    type: LoadBalancer
    # @schema
    # type: [null, integer]
    # @schema
    # -- Configure a specific nodePort for insecure HTTP traffic on the shared LB service
    insecureNodePort: ~
    # @schema
    # type: [null, integer]
    # @schema
    # -- Configure a specific nodePort for secure HTTPS traffic on the shared LB service
    secureNodePort: ~
    # @schema
    # type: [null, string]
    # @schema
    # -- Configure a specific loadBalancerClass on the shared LB service (requires Kubernetes 1.24+)
    loadBalancerClass: ~
    # @schema
    # type: [null, string]
    # @schema
    # -- Configure a specific loadBalancerIP on the shared LB service
    loadBalancerIP: ~
    # @schema
    # type: [null, boolean]
    # @schema
    # -- Configure if node port allocation is required for LB service
    # ref: https://kubernetes.io/docs/concepts/services-networking/service/#load-balancer-nodeport-allocation
    allocateLoadBalancerNodePorts: ~
    # -- Control how traffic from external sources is routed to the LoadBalancer Kubernetes Service for Cilium Ingress in shared mode.
    # Valid values are "Cluster" and "Local".
    # ref: https://kubernetes.io/docs/reference/networking/virtual-ips/#external-traffic-policy
    externalTrafficPolicy: Cluster
  # Host Network related configuration
  hostNetwork:
    # -- Configure whether the Envoy listeners should be exposed on the host network.
    enabled: false
    # -- Configure a specific port on the host network that gets used for the shared listener.
    sharedListenerPort: 8080
    # Specify the nodes where the Ingress listeners should be exposed
    nodes:
      # -- Specify the labels of the nodes where the Ingress listeners should be exposed
      #
      # matchLabels:
      #   kubernetes.io/os: linux
      #   kubernetes.io/hostname: kind-worker
      matchLabels: {}
gatewayAPI:
  # -- Enable support for Gateway API in cilium
  # This will automatically set enable-envoy-config as well.
  enabled: false
  # -- Enable proxy protocol for all GatewayAPI listeners. Note that _only_ Proxy protocol traffic will be accepted once this is enabled.
  enableProxyProtocol: false
  # -- Enable Backend Protocol selection support (GEP-1911) for Gateway API via appProtocol.
  enableAppProtocol: false
  # -- Enable ALPN for all listeners configured with Gateway API. ALPN will attempt HTTP/2, then HTTP 1.1.
  # Note that this will also enable `appProtocol` support, and services that wish to use HTTP/2 will need to indicate that via their `appProtocol`.
  enableAlpn: false
  # -- The number of additional GatewayAPI proxy hops from the right side of the HTTP header to trust when determining the origin client's IP address.
  xffNumTrustedHops: 0
  # -- Control how traffic from external sources is routed to the LoadBalancer Kubernetes Service for all Cilium GatewayAPI Gateway instances. Valid values are "Cluster" and "Local".
  # Note that this value will be ignored when `hostNetwork.enabled == true`.
  # ref: https://kubernetes.io/docs/reference/networking/virtual-ips/#external-traffic-policy
  externalTrafficPolicy: Cluster
  gatewayClass:
    # -- Enable creation of GatewayClass resource
    # The default value is 'auto' which decides according to presence of gateway.networking.k8s.io/v1/GatewayClass in the cluster.
    # Other possible values are 'true' and 'false', which will either always or never create the GatewayClass, respectively.
    create: auto
  # -- SecretsNamespace is the namespace in which envoy SDS will retrieve TLS secrets from.
  secretsNamespace:
    # -- Create secrets namespace for Gateway API.
    create: true
    # -- Name of Gateway API secret namespace.
    name: cilium-secrets
    # -- Enable secret sync, which will make sure all TLS secrets used by Ingress are synced to secretsNamespace.name.
    # If disabled, TLS secrets must be maintained externally.
    sync: true
  # Host Network related configuration
  hostNetwork:
    # -- Configure whether the Envoy listeners should be exposed on the host network.
    enabled: false
    # Specify the nodes where the Ingress listeners should be exposed
    nodes:
      # -- Specify the labels of the nodes where the Ingress listeners should be exposed
      #
      # matchLabels:
      #   kubernetes.io/os: linux
      #   kubernetes.io/hostname: kind-worker
      matchLabels: {}
# -- Enables the fallback compatibility solution for when the xt_socket kernel
# module is missing and it is needed for the datapath L7 redirection to work
# properly. See documentation for details on when this can be disabled:
# https://docs.cilium.io/en/stable/operations/system_requirements/#linux-kernel.

externalIPs:
  # -- Enable ExternalIPs service support.
  enabled: false
# fragmentTracking enables IPv4 fragment tracking support in the datapath.
# fragmentTracking: true
ipam:
  # -- Configure IP Address Management mode.
  # ref: https://docs.cilium.io/en/stable/network/concepts/ipam/
  mode: "cluster-pool"
  # -- Maximum rate at which the CiliumNode custom resource is updated.
  ciliumNodeUpdateRate: "15s"
  # -- Pre-allocation settings for IPAM in Multi-Pool mode
  multiPoolPreAllocation: ""
  # -- Install ingress/egress routes through uplink on host for Pods when working with delegated IPAM plugin.
  installUplinkRoutesForDelegatedIPAM: false
  operator:
    # @schema
    # type: [array, string]
    # @schema
    # -- IPv4 CIDR list range to delegate to individual nodes for IPAM.
    clusterPoolIPv4PodCIDRList: ["10.0.0.0/8"]
    # -- IPv4 CIDR mask size to delegate to individual nodes for IPAM.
    clusterPoolIPv4MaskSize: 24
    # @schema
    # type: [array, string]
    # @schema
    # -- IPv6 CIDR list range to delegate to individual nodes for IPAM.
    clusterPoolIPv6PodCIDRList: ["fd00::/104"]
    # -- IPv6 CIDR mask size to delegate to individual nodes for IPAM.
    clusterPoolIPv6MaskSize: 120
    # -- IP pools to auto-create in multi-pool IPAM mode.
    autoCreateCiliumPodIPPools: {}
    #   default:
    #     ipv4:
    #       cidrs:
    #         - 10.10.0.0/8
    #       maskSize: 24
    #   other:
    #     ipv6:
    #       cidrs:
    #         - fd00:100::/80
    #       maskSize: 96
    # @schema
    # type: [null, integer]
    # @schema
    # -- (int) The maximum burst size when rate limiting access to external APIs.
    # Also known as the token bucket capacity.
    # @default -- `20`
    externalAPILimitBurstSize: ~
    # @schema
    # type: [null, number]
    # @schema
    # -- (float) The maximum queries per second when rate limiting access to
    # external APIs. Also known as the bucket refill rate, which is used to
    # refill the bucket up to the burst size capacity.
    # @default -- `4.0`
    externalAPILimitQPS: ~
# -- defaultLBServiceIPAM indicates the default LoadBalancer Service IPAM when
# no LoadBalancer class is set. Applicable values: lbipam, nodeipam, none
# @schema
# type: [string]
# @schema
defaultLBServiceIPAM: lbipam
nodeIPAM:
  # -- Configure Node IPAM
  # ref: https://docs.cilium.io/en/stable/network/node-ipam/
  enabled: false
# @schema
# type: [null, string]
# @schema
# -- The api-rate-limit option can be used to overwrite individual settings of the default configuration for rate limiting calls to the Cilium Agent API
apiRateLimit: ~
# -- Configure the eBPF-based ip-masq-agent
ipMasqAgent:
  enabled: false
# the config of nonMasqueradeCIDRs
# config:
#   nonMasqueradeCIDRs: []
#   masqLinkLocal: false
#   masqLinkLocalIPv6: false

# iptablesLockTimeout defines the iptables "--wait" option when invoked from Cilium.
# iptablesLockTimeout: "5s"
ipv4:
  # -- Enable IPv4 support.
  enabled: true
ipv6:
  # -- Enable IPv6 support.
  enabled: false
# -- Configure Kubernetes specific configuration
k8s:
  # -- requireIPv4PodCIDR enables waiting for Kubernetes to provide the PodCIDR
  # range via the Kubernetes node resource
  requireIPv4PodCIDR: false
  # -- requireIPv6PodCIDR enables waiting for Kubernetes to provide the PodCIDR
  # range via the Kubernetes node resource
  requireIPv6PodCIDR: false
# -- Keep the deprecated selector labels when deploying Cilium DaemonSet.
l2NeighDiscovery:
  # -- Enable L2 neighbor discovery in the agent
  enabled: true
  # -- Override the agent's default neighbor resolution refresh period.
  refreshPeriod: "30s"
# -- Enable Layer 7 network policy.
l7Proxy: true
# -- Enable Local Redirect Policy.
enableIPv4Masquerade: true
# -- Enables masquerading of IPv6 traffic leaving the node from endpoints.
enableIPv6Masquerade: true
# -- Enables masquerading to the source of the route for traffic leaving the node from endpoints.
enableMasqueradeRouteSource: false
# -- Enables IPv4 BIG TCP support which increases maximum IPv4 GSO/GRO limits for nodes and pods
enableIPv4BIGTCP: false
# -- Enables IPv6 BIG TCP support which increases maximum IPv6 GSO/GRO limits for nodes and pods
enableIPv6BIGTCP: false
nat:
  # -- Number of the top-k SNAT map connections to track in Cilium statedb.
  mapStatsEntries: 32
  # -- Interval between how often SNAT map is counted for stats.
  mapStatsInterval: 30s
egressGateway:
  # -- Enables egress gateway to redirect and SNAT the traffic that leaves the
  # cluster.
  enabled: false
  # -- Time between triggers of egress gateway state reconciliations
  reconciliationTriggerInterval: 1s
  # -- Maximum number of entries in egress gateway policy map
  # maxPolicyEntries: 16384
loadBalancer:
  # -- standalone enables the standalone L4LB which does not connect to
  # kube-apiserver.
  # standalone: false

  # -- algorithm is the name of the load balancing algorithm for backend
  # selection e.g. random or maglev
  # algorithm: random

  # -- mode is the operation mode of load balancing for remote backends
  # e.g. snat, dsr, hybrid
  # mode: snat

  # -- acceleration is the option to accelerate service handling via XDP
  # Applicable values can be: disabled (do not use XDP), native (XDP BPF
  # program is run directly out of the networking driver's early receive
  # path), or best-effort (use native mode XDP acceleration on devices
  # that support it).
  acceleration: disabled
  # -- dsrDispatch configures whether IP option or IPIP encapsulation is
  # used to pass a service IP and port to remote backend
  # dsrDispatch: opt

  # -- serviceTopology enables K8s Topology Aware Hints -based service
  # endpoints filtering
  # serviceTopology: false

  # -- experimental enables support for the experimental load-balancing
  # control-plane.
  experimental: false
  # -- L7 LoadBalancer
  l7:
    # -- Enable L7 service load balancing via envoy proxy.
    # The request to a k8s service, which has specific annotation e.g. service.cilium.io/lb-l7,
    # will be forwarded to the local backend proxy to be load balanced to the service endpoints.
    # Please refer to docs for supported annotations for more configuration.
    #
    # Applicable values:
    #   - envoy: Enable L7 load balancing via envoy proxy. This will automatically set enable-envoy-config as well.
    #   - disabled: Disable L7 load balancing by way of service annotation.
    backend: disabled
    # -- List of ports from service to be automatically redirected to above backend.
    # Any service exposing one of these ports will be automatically redirected.
    # Fine-grained control can be achieved by using the service annotation.
    ports: []
    # -- Default LB algorithm
    # The default LB algorithm to be used for services, which can be overridden by the
    # service annotation (e.g. service.cilium.io/lb-l7-algorithm)
    # Applicable values: round_robin, least_request, random
    algorithm: round_robin
# -- Configure N-S k8s service loadbalancing
dashboards:
  enabled: false
  label: grafana_dashboard
  # @schema
  # type: [null, string]
  # @schema
  namespace: ~
  labelValue: "1"
  annotations: {}
# Configure Cilium Envoy options.


securityContext:
  # -- User to run the pod with
  # runAsUser: 0
  # -- Run the pod with elevated privileges
  privileged: false
  # -- SELinux options for the `cilium-agent` and init containers
  seLinuxOptions:
    level: 's0'
    # Running with spc_t since we have removed the privileged mode.
    # Users can change it to a different type as long as they have the
    # type available on the system.
    type: 'spc_t'
  capabilities:
    # -- Capabilities for the `cilium-agent` container
    ciliumAgent:
      # Use to set socket permission
      - CHOWN
      # Used to terminate envoy child process
      - KILL
      # Used since cilium modifies routing tables, etc...
      - NET_ADMIN
      # Used since cilium creates raw sockets, etc...
      - NET_RAW
      # Used since cilium monitor uses mmap
      - IPC_LOCK
      # Used in iptables. Consider removing once we are iptables-free
      - SYS_MODULE
      # Needed to switch network namespaces (used for health endpoint, socket-LB).
      # We need it for now but might not need it for >= 5.11 specially
      # for the 'SYS_RESOURCE'.
      # In >= 5.8 there's already BPF and PERMON capabilities
      - SYS_ADMIN
      # Could be an alternative for the SYS_ADMIN for the RLIMIT_NPROC
      - SYS_RESOURCE
      # Both PERFMON and BPF requires kernel 5.8, container runtime
      # cri-o >= v1.22.0 or containerd >= v1.5.0.
      # If available, SYS_ADMIN can be removed.
      #- PERFMON
      #- BPF
      # Allow discretionary access control (e.g. required for package installation)
      - DAC_OVERRIDE
      # Allow to set Access Control Lists (ACLs) on arbitrary files (e.g. required for package installation)
      - FOWNER
      # Allow to execute program that changes GID (e.g. required for package installation)
      - SETGID
      # Allow to execute program that changes UID (e.g. required for package installation)
      - SETUID
    # -- Capabilities for the `mount-cgroup` init container
    mountCgroup:
      # Only used for 'mount' cgroup
      - SYS_ADMIN
      # Used for nsenter
      - SYS_CHROOT
      - SYS_PTRACE
    # -- capabilities for the `apply-sysctl-overwrites` init container
    applySysctlOverwrites:
      # Required in order to access host's /etc/sysctl.d dir
      - SYS_ADMIN
      # Used for nsenter
      - SYS_CHROOT
      - SYS_PTRACE
    # -- Capabilities for the `clean-cilium-state` init container
    cleanCiliumState:
      # Most of the capabilities here are the same ones used in the
      # cilium-agent's container because this container can be used to
      # uninstall all Cilium resources, and therefore it is likely that
      # will need the same capabilities.
      # Used since cilium modifies routing tables, etc...
      - NET_ADMIN
      # Used in iptables. Consider removing once we are iptables-free
      - SYS_MODULE
      # We need it for now but might not need it for >= 5.11 specially
      # for the 'SYS_RESOURCE'.
      # In >= 5.8 there's already BPF and PERMON capabilities
      - SYS_ADMIN
      # Could be an alternative for the SYS_ADMIN for the RLIMIT_NPROC
      - SYS_RESOURCE
      # Both PERFMON and BPF requires kernel 5.8, container runtime
      # cri-o >= v1.22.0 or containerd >= v1.5.0.
      # If available, SYS_ADMIN can be removed.
      #- PERFMON
      #- BPF

nat46x64Gateway:
  # -- Enable RFC8215-prefixed translation
  enabled: false
# -- EnableHighScaleIPcache enables the special ipcache mode for high scale
# clusters. The ipcache content will be reduced to the strict minimum and
# traffic will be encapsulated to carry security identities.
debug:
  # -- Enable debug logging
  enabled: false
  # @schema
  # type: [null, string]
  # @schema
  # -- Configure verbosity levels for debug logging
  # This option is used to enable debug messages for operations related to such
  # sub-system such as (e.g. kvstore, envoy, datapath or policy), and flow is
  # for enabling debug messages emitted per request, message and connection.
  # Multiple values can be set via a space-separated string (e.g. "datapath envoy").
  #
  # Applicable values:
  # - flow
  # - kvstore
  # - envoy
  # - datapath
  # - policy
  verbose: ~