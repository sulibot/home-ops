---
# talconfig template rendered with jinja2 before invoking talhelper.

clusterName: "{{ clusterName }}"
talosVersion: "{{ talosVersion }}"
kubernetesVersion: "{{ kubernetesVersion }}"

# The VIP for the control plane.
endpoint: "{{ endpoint }}"

{% set endpoint_host_port = endpoint.split('://')[1] %}
{% if endpoint_host_port.startswith('[') %}
{% set control_plane_vip = endpoint_host_port.split(']')[0].lstrip('[') %}
{% else %}
{% set control_plane_vip = endpoint_host_port.split(':')[0] %}
{% endif %}

# Define dual-stack VIPs for kube-apiserver
{% set control_plane_vip_ipv4 = "10.0." + cluster_id|string + ".10" %}
{% set control_plane_vip_ipv6 = "fd00:" + cluster_id|string + "::10" %}

# Tell talhelper where to find the encrypted secrets file.
secretsFile: "{{ secret_file }}"

# Define the dual-stack Pod and Service CIDRs for Kubernetes.
# IPv6 must be first to match the advertise address family (IPv6 VIP)
clusterPodNets:
  - "{{ pods_ipv6 }}"
  - "{{ pods_ipv4 }}"
clusterServiceNets:
  - "{{ services_ipv6 }}"
  - "{{ services_ipv4 }}"

# Define the nodes for the cluster.
nodes:
{% for node in nodes %}
  - hostname: "{{ node.hostname }}"
    ipAddress: "{{ node.ipAddress }}"
    controlPlane: {{ "true" if node.controlPlane else "false" }}
    installDisk: "{{ node.installDisk | default('/dev/sda') }}"
    networkInterfaces:
      # Public/management network - must be first for proper routing
      - interface: ens18
        addresses:
{% if node.publicIPv4 %}
          - "{{ node.publicIPv4 }}/24"
{% endif %}
{% if node.publicIPv6 %}
          - "{{ node.publicIPv6 }}/64"
{% endif %}
{% if node.controlPlane %}
        # Dual-stack VIPs for control plane HA (managed by Talos)
        vip:
          ip: {{ control_plane_vip }}
        # FUTURE: When Talos supports multiple VIPs via vip.additionalIPs, add IPv4 VIP here
        # For now, IPv4 clients must connect via the primary IPv6 VIP (kube-apiserver listens on ::)
{% endif %}
{% if node.publicGatewayIPv4 or node.publicGatewayIPv6 %}
        routes:
{% if node.publicGatewayIPv4 %}
          - network: 0.0.0.0/0
            gateway: "{{ node.publicGatewayIPv4 }}"
            metric: 1024
{% endif %}
{% if node.publicGatewayIPv6 %}
          - network: "::/0"
            gateway: "{{ node.publicGatewayIPv6 }}"
            metric: 1024
{% endif %}
{% endif %}
        mtu: {{ node.publicMTU | default(1500) }}
      # Mesh network - internal cluster communication only, no gateway
      - interface: ens19
        addresses:
{% if node.meshIPv4 %}
          - "{{ node.meshIPv4 }}/24"
{% endif %}
{% if node.meshIPv6 %}
          - "{{ node.meshIPv6 }}/64"
{% endif %}
        routes:
          # Route to Ceph cluster network via ens19
          - network: fc00:20::/64
            metric: 1024
        mtu: {{ node.meshMTU | default(1500) }}
    nameservers:
{% if dns_server_ipv6 %}
      - "{{ dns_server_ipv6 }}"
{% endif %}
{% if dns_server_ipv4 %}
      - "{{ dns_server_ipv4 }}"
{% endif %}
    patches:
      # Machine-level configuration for all nodes
      - |-
        machine:
          certSANs:
            - 127.0.0.1
            - ::1
            - localhost
            - {{ node.hostname }}
            - {{ node.hostname }}.{{ clusterName }}
{% if node.publicIPv6 %}
            - {{ node.publicIPv6 }}
{% endif %}
{% if node.publicIPv4 %}
            - {{ node.publicIPv4 }}
{% endif %}
{% if node.meshIPv6 %}
            - {{ node.meshIPv6 }}
{% endif %}
{% if node.meshIPv4 %}
            - {{ node.meshIPv4 }}
{% endif %}
{% if node.controlPlane %}
            - {{ control_plane_vip_ipv6 }}
            - {{ control_plane_vip_ipv4 }}
{% endif %}
          kubelet:
            # Explicitly set cluster DNS to match the dual-stack service CIDR
            # DNS service is at the 10th IP in each service subnet
            clusterDNS:
              - {{ services_ipv6.split('/')[0] }}a
              - {{ services_ipv4.split('/')[0].rsplit('.', 1)[0] }}.10
            # Explicitly set the node IP to avoid ambiguity when VIP is on same interface
            # Using /128 and /32 masks ensures kubelet uses only the specific node IPs, not the VIP
            nodeIP:
              validSubnets:
{% if node.publicIPv6 %}
                - "{{ node.publicIPv6 }}/128"
{% endif %}
{% if node.publicIPv4 %}
                - "{{ node.publicIPv4 }}/32"
{% endif %}
          sysctls:
            # Increase the maximum number of open file descriptors
            fs.file-max: "1000000"
            # Increase inotify limits for watching files (useful for kubelet and other agents)
            fs.inotify.max_user_watches: "524288"
            # Increase the size of the connection tracking table. Essential for Cilium
            net.netfilter.nf_conntrack_max: "1048576"
            # Increase the maximum number of connections the kernel will queue
            net.core.somaxconn: "32768"
            # Required for IP-in-IP encapsulation if used
            net.ipv4.ip_forward: "1"
            net.ipv6.conf.all.forwarding: "1"
{% if node.controlPlane %}
      # Control plane specific: Override service subnets with dual-stack configuration
      # IPv6 must be first to match the advertise address family (IPv6 VIP)
      - |-
        cluster:
          network:
            serviceSubnets:
              - {{ services_ipv6 }}
              - {{ services_ipv4 }}
            # Skip default CNI installation - we'll install Cilium manually
            cni:
              name: none
          # Disable kube-proxy because we are using Cilium
          proxy:
            disabled: true
          apiServer:
            # Configure kube-apiserver for dual-stack VIPs
            # Listen on both IPv4 and IPv6, advertise primary (IPv6) VIP
            certSANs:
              - 127.0.0.1
              - ::1
              - localhost
              - {{ node.hostname }}
              - {{ node.hostname }}.{{ clusterName }}
              - kubernetes
              - kubernetes.default
              - kubernetes.default.svc
              - kubernetes.default.svc.cluster.local
              - {{ control_plane_vip_ipv6 }}
              - {{ control_plane_vip_ipv4 }}
{% if node.publicIPv6 and node.publicIPv6 != control_plane_vip_ipv6 %}
              - {{ node.publicIPv6 }}
{% endif %}
{% if node.publicIPv4 and node.publicIPv4 != control_plane_vip_ipv4 %}
              - {{ node.publicIPv4 }}
{% endif %}
{% if node.meshIPv6 %}
              - {{ node.meshIPv6 }}
{% endif %}
{% if node.meshIPv4 %}
              - {{ node.meshIPv4 }}
{% endif %}
            extraArgs:
              # Listen on all IPv6 interfaces (includes IPv4-mapped addresses in dual-stack)
              # Using :: enables listening on both IPv4 and IPv6 in dual-stack mode
              bind-address: "::"
              # Advertise the primary IPv6 VIP to cluster components
              advertise-address: "{{ control_plane_vip }}"
            admissionControl:
              # Enable MutatingAdmissionWebhook for volsync and other operators
              - name: PodSecurity
                configuration:
                  apiVersion: pod-security.admission.config.k8s.io/v1alpha1
                  kind: PodSecurityConfiguration
                  defaults:
                    enforce: "baseline"
                    enforce-version: "latest"
                    audit: "restricted"
                    audit-version: "latest"
                    warn: "restricted"
                    warn-version: "latest"
                  exemptions:
                    namespaces:
                      - volsync-system
                      - actions-runner-system
                    runtimeClasses: []
                    usernames: []
{% endif %}
{% endfor %}
