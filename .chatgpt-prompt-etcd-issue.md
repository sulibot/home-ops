# Talos Kubernetes Cluster: etcd Formation Issue - Only 1/3 Control Planes Join

## Problem Summary
When bootstrapping a 3-node Talos Linux control plane cluster, only 1 out of 3 control plane nodes successfully joins the etcd cluster. The other 2 nodes either get stuck as learners or fail to start etcd entirely. This is a **recurring issue** - it doesn't always happen, but occurs frequently enough to block reliable cluster deployment.

## Environment
- **Talos Linux**: v1.12.1
- **Kubernetes**: v1.34.1
- **etcd**: v3.6.7 (included in Talos)
- **Infrastructure**: Proxmox VMs with IPv6-first dual-stack networking
- **Network**: ULA (fd00:101::/48) for cluster, GUA (2600:1700:ab1a:500d::/64) for internet
- **Control Plane Nodes**: 3 nodes (solcp01, solcp02, solcp03)

## Current Behavior (Last Failed Bootstrap)

### Bootstrap Timeline
1. **T+0s**: Kubernetes API becomes responsive
2. **T+110s**: 2 nodes registered (not all 3)
3. **T+110s - T+410s**: Waiting for control plane endpoints - stuck at **1/3** for entire 5 minutes
4. **T+410s**: Timeout and abort

### etcd Cluster State When Failed
```bash
$ talosctl -n fd00:101::11 etcd members
NODE           ID                 HOSTNAME   LEARNER
fd00:101::11   0e5c6673a1613e85   solcp01    false    # ✓ Full voting member
fd00:101::11   b3eb779549017612   solcp03    true     # ✗ Stuck as learner
# solcp02 missing entirely - never joined
```

### Service Status
**solcp01** (fd00:101::11):
- etcd: Running, OK
- kubelet: Running, OK
- Status: **Bootstrap node, fully joined**

**solcp02** (fd00:101::12):
```
SERVICE   STATE       HEALTH   LAST EVENT
etcd      Preparing   ?        Running pre state (6m45s ago)
```
- etcd stuck in "Preparing" state for 6+ minutes
- Logs show: `etcd is waiting to join the cluster`

**solcp03** (fd00:101::13):
```
SERVICE   STATE     HEALTH   LAST EVENT
etcd      Running   Fail     Health check failed: etcdserver: rpc not supported for learner
```
- etcd running as learner but health check fails
- RAFT INDEX: 2168, RAFT APPLIED INDEX: 2168 (fully synced)
- Database: 7.4 MB (100% in use)

### Kubernetes Service Endpoints
```bash
$ kubectl get endpoints kubernetes -n default
ADDRESSES
- fd00:101::11    # Only solcp01 registered
# solcp02 and solcp03 missing - API servers not in service
```

## Configuration Files

### 1. Cluster Topology: `talos/clusters/cluster-101/talenv.yaml`
```yaml
nodes:
  - controlPlane: true
    hostname: solcp01
    ipAddress: 10.101.0.11
    publicIPv6: fd00:101::11
    loopbackIPv6: fd00:101:fe::11
  - controlPlane: true
    hostname: solcp02
    ipAddress: 10.101.0.12
    publicIPv6: fd00:101::12
    loopbackIPv6: fd00:101:fe::12
  - controlPlane: true
    hostname: solcp03
    ipAddress: 10.101.0.13
    publicIPv6: fd00:101::13
    loopbackIPv6: fd00:101:fe::13
```

### 2. etcd Configuration: `terraform/infra/modules/talos_config/main.tf` (lines 261-266)
```hcl
etcd = {
  advertisedSubnets = [
    "fd00:${var.cluster_id}:fe::/64",  # Loopback subnet
    "fd00:${var.cluster_id}::/64"      # Public subnet
  ]
}
```
**Note**: No explicit `initialCluster` configuration - relies on Talos automatic discovery

### 3. Bootstrap Logic: `terraform/infra/modules/talos_bootstrap/main.tf`

**Bootstrap Trigger** (line 26):
```hcl
resource "talos_machine_bootstrap" "cluster" {
  client_configuration = var.client_configuration
  node                 = local.first_cp_node.ipv6  # fd00:101::11
  endpoint             = local.first_cp_node.ipv6
}
```
Bootstraps **only solcp01** - other nodes join automatically

**Wait Logic** (lines 77-108):
```bash
# 1. Wait for etcd cluster formation (up to 10 minutes)
EXPECTED_CP_COUNT=3
for i in {1..120}; do
  ETCD_MEMBER_COUNT=$(talosctl -n fd00:101::11 etcd members 2>/dev/null | grep -c "false$" || echo "0")
  if [ "$ETCD_MEMBER_COUNT" -ge "$EXPECTED_CP_COUNT" ]; then
    echo "✓ All 3 etcd members joined"
    break
  fi
  sleep 5
done

# 2. Wait for control plane API servers in kubernetes service (5 minutes)
for i in {1..60}; do
  CP_ENDPOINT_COUNT=$(kubectl get endpoints kubernetes -n default -o jsonpath='{.subsets[*].addresses[*].ip}' | wc -w)
  if [ "$CP_ENDPOINT_COUNT" -ge 3 ]; then
    echo "✓ All 3 control plane API servers registered"
    exit 0
  fi
  sleep 5
done
```

### 4. Generated Machine Config: `talos/clusters/cluster-101/controlplane.yaml` (excerpt)
```yaml
cluster:
  controlPlane:
    endpoint: https://[fd00:101::10]:6443
  etcd:
    ca:
      crt: <base64-encoded-cert>
      key: <base64-encoded-key>
    advertisedSubnets:
      - fd00:101:fe::/64
      - fd00:101::/64
```

## Network Connectivity

All control plane nodes can reach each other:
- Port 2379 (etcd client): Accessible
- Port 2380 (etcd peer): Accessible
- Port 6443 (kube-apiserver): Accessible

Verified via:
```bash
$ kubectl get nodes
NAME      STATUS   ROLES           AGE
solcp01   Ready    control-plane   5m
solcp02   Ready    control-plane   5m
solcp03   Ready    control-plane   5m
```
Nodes register successfully, but etcd doesn't form.

## Related Known Issues

From GitHub/Talos documentation:
1. **[siderolabs/talos#5350](https://github.com/siderolabs/talos/issues/5350)**: "etcd failure to join the cluster" - 3rd node gets stuck with "too many learner members"
2. **[siderolabs/talos#5942](https://github.com/siderolabs/talos/issues/5942)**: "Intermittent failure to form etcd cluster" - ~50% success rate for 3-node formation

## Bootstrap Output (Last Attempt)
```
---[ Wait for Kubernetes API ]---
⏳ Waiting for talosctl to generate kubeconfig...
✓ Kubeconfig generated.
⏳ Waiting for Kubernetes API server and node registration...
  ... attempt 1/60, retrying in 10s (waiting for nodes to register)
  ... attempt 2/60, retrying in 10s (waiting for nodes to register)
  [attempts 3-10 omitted]
  ... attempt 11/60, retrying in 10s (waiting for nodes to register)
✓ Kubernetes API is healthy! (2 node(s) registered)
⏳ Waiting for all 3 control plane API servers to join kubernetes service...
  ... 1/3 endpoints ready, retrying in 5s
  [repeated 60 times - stuck for entire 5 minutes]
❌ Control plane endpoint registration timed out after 5 minutes. Aborting.
```

## Questions

1. **Why does solcp03 become a learner but never get promoted?** It's fully synced (RAFT INDEX matches), but etcd doesn't auto-promote it to a voting member.

2. **Why does solcp02's etcd never start?** It gets stuck in "Preparing" state with "Running pre state" for 6+ minutes, showing "etcd is waiting to join the cluster" but never progresses.

3. **Is the lack of explicit `initialCluster` configuration the issue?** Should we explicitly set `cluster.etcd.initialCluster` with all 3 members instead of relying on Talos automatic discovery?

4. **Is this a timing issue or a configuration issue?** The etcd formation should take seconds to ~2 minutes max, not 5-10 minutes. What's blocking the automatic joining/promotion?

5. **Should bootstrap happen differently for 3-node clusters?** Currently bootstrapping only solcp01 - should we bootstrap all 3 simultaneously or in a different order?

## Request

Please analyze this configuration and provide:
1. **Root cause** of why etcd cluster formation fails intermittently
2. **Specific configuration changes** needed to fix this (with exact file paths and code snippets)
3. **Whether the bootstrap process itself needs to change** (e.g., should we bootstrap differently for multi-node control planes?)
4. **Any Talos-specific etcd configuration** we're missing that would ensure reliable 3-node cluster formation

File locations for reference:
- Machine config: `terraform/infra/modules/talos_config/main.tf`
- Bootstrap logic: `terraform/infra/modules/talos_bootstrap/main.tf`
- Generated configs: `talos/clusters/cluster-101/controlplane.yaml`
- Cluster topology: `talos/clusters/cluster-101/talenv.yaml`
